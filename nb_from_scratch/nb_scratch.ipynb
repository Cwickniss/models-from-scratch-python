{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### **1. Import Libraries**\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "### **2. Load Iris Dataset**\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Access the features and target variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert the data to a dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "df\n",
    "\n",
    "### **3. Build NB Classifier from Scratch**\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probabilities = None\n",
    "        self.feature_probabilities = None\n",
    "        self.classifier_type = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y, classifier_type='multinomial'):\n",
    "        \"\"\"\n",
    "        Fits the Naive Bayes classifier to the data.\n",
    "\n",
    "        Args:\n",
    "            X: A numpy array of the training data.\n",
    "            y: A numpy array of the training labels.\n",
    "            classifier_type: Type of Naive Bayes classifier. Options: 'multinomial', 'bernoulli', 'gaussian'.\n",
    "            \n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.y = y\n",
    "        self.classifier_type = classifier_type.lower()\n",
    "        \n",
    "        # Calculate the class probabilities.\n",
    "        class_counts = np.bincount(y)\n",
    "        self.class_probabilities = class_counts / np.sum(class_counts)\n",
    "        \n",
    "        # Calculate the feature probabilities based on the specified classifier type.\n",
    "        if self.classifier_type == 'multinomial':\n",
    "            self.feature_probabilities = {}\n",
    "            for class_label in np.unique(y):\n",
    "                X_class = X[y == class_label]\n",
    "                X_class_flat = X_class.flatten().astype(int)  # Convert X_class to integers\n",
    "                feature_counts = np.bincount(X_class_flat, minlength=X.shape[1])\n",
    "                self.feature_probabilities[class_label] = feature_counts / np.sum(feature_counts, axis=0)\n",
    "        elif self.classifier_type == 'bernoulli':\n",
    "            self.feature_probabilities = {}\n",
    "            for class_label in np.unique(y):\n",
    "                X_class = X[y == class_label]\n",
    "                feature_probabilities = (X_class.sum(axis=0) + 1) / (X_class.shape[0] + 2)\n",
    "                self.feature_probabilities[class_label] = feature_probabilities\n",
    "        elif self.classifier_type == 'gaussian':\n",
    "            self.feature_probabilities = {}\n",
    "            for class_label in np.unique(y):\n",
    "                X_class = X[y == class_label]\n",
    "                class_mean = np.mean(X_class, axis=0)\n",
    "                class_std = np.std(X_class, axis=0)\n",
    "                self.feature_probabilities[class_label] = (class_mean, class_std)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid classifier_type. Supported types are 'multinomial', 'bernoulli', and 'gaussian'.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class of the input data.\n",
    "\n",
    "        Args:\n",
    "            X: A numpy array of the input data.\n",
    "\n",
    "        Returns:\n",
    "            A numpy array of the predicted classes.\n",
    "        \"\"\"\n",
    "        if self.classifier_type == 'multinomial':\n",
    "            # Calculate the probability of each class given the input data for Multinomial Naive Bayes.\n",
    "            class_probabilities = np.zeros((X.shape[0], len(self.class_probabilities)))\n",
    "            for class_label in np.unique(self.y):  # Use self.y instead of y\n",
    "                X_class = X[self.y == class_label]  # Use self.y instead of y\n",
    "                X_class_flat = X_class.flatten().astype(float)\n",
    "                feature_counts = np.bincount(X_class_flat.astype(int), minlength=X.shape[1])\n",
    "                self.feature_probabilities[class_label] = feature_counts / np.sum(feature_counts, axis=0)\n",
    "                class_probabilities[:, class_label] = np.log(self.class_probabilities[class_label]) + np.sum(np.log(self.feature_probabilities[class_label][X.astype(bool)]), axis=1)\n",
    "\n",
    "        elif self.classifier_type == 'bernoulli':\n",
    "            # Calculate the probability of each class given the input data for Bernoulli Naive Bayes.\n",
    "            class_probabilities = np.zeros((X.shape[0], len(self.class_probabilities)))\n",
    "            for class_label in np.unique(self.y):  # Use self.y instead of y\n",
    "                X_class = X[self.y == class_label]  # Use self.y instead of y\n",
    "                feature_probabilities = self.feature_probabilities[class_label]\n",
    "                class_probabilities[:, class_label] = np.log(self.class_probabilities[class_label]) + np.sum(np.log(feature_probabilities[X.astype(bool)]), axis=1)\n",
    "\n",
    "        elif self.classifier_type == 'gaussian':\n",
    "            # Calculate the probability of each class given the input data for Gaussian Naive Bayes.\n",
    "            class_probabilities = np.zeros((X.shape[0], len(self.class_probabilities)))\n",
    "            for class_label in np.unique(self.y):  # Use self.y instead of y\n",
    "                X_class = X[self.y == class_label]  # Use self.y instead of y\n",
    "                class_mean, class_std = self.feature_probabilities[class_label]\n",
    "                class_probabilities[:, class_label] = np.log(self.class_probabilities[class_label]) + np.sum(-0.5 * np.log(2 * np.pi * class_std) - 0.5 * ((X - class_mean) ** 2) / (class_std ** 2), axis=1)\n",
    "                \n",
    "        else:\n",
    "            raise ValueError(\"Invalid classifier_type. Supported types are 'multinomial', 'bernoulli', and 'gaussian'.\")\n",
    "        \n",
    "        # Predict the class with the highest probability.\n",
    "        predicted_classes = np.argmax(class_probabilities, axis=1)\n",
    "        return predicted_classes\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.features = []\n",
    "        self.likelihoods = {}\n",
    "        self.class_priors = {}\n",
    "        self.pred_priors = {}\n",
    "\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        self.train_size = 0\n",
    "        self.num_feats = 0\n",
    "\n",
    "    def fit(self, X, y, classifier_type='multinomial'):\n",
    "        self.features = list(X.columns)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.train_size = X.shape[0]\n",
    "        self.num_feats = X.shape[1]\n",
    "\n",
    "        if classifier_type == 'multinomial':\n",
    "            self._fit_multinomial()\n",
    "        elif classifier_type == 'bernoulli':\n",
    "            self._fit_bernoulli()\n",
    "        elif classifier_type == 'gaussian':\n",
    "            self._fit_gaussian()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid classifier_type. Supported types are 'multinomial', 'bernoulli', and 'gaussian'.\")\n",
    "\n",
    "    def _fit_multinomial(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(self.y_train)\n",
    "\n",
    "        for feature in self.features:\n",
    "            self.likelihoods[feature] = {}\n",
    "            self.pred_priors[feature] = {}\n",
    "\n",
    "            for feat_val in np.unique(self.X_train[feature]):\n",
    "                self.pred_priors[feature][feat_val] = 0\n",
    "\n",
    "                for outcome in np.unique(y_encoded):\n",
    "                    self.likelihoods[feature][feat_val + '_' + str(outcome)] = 0\n",
    "                    self.class_priors[outcome] = 0\n",
    "\n",
    "        self._calc_class_prior_multinomial(y_encoded)\n",
    "        self._calc_likelihoods_multinomial(y_encoded)\n",
    "        self._calc_predictor_prior_multinomial()\n",
    "\n",
    "    def _calc_class_prior_multinomial(self, y_encoded):\n",
    "        class_counts = np.bincount(y_encoded)\n",
    "        total_count = np.sum(class_counts)\n",
    "\n",
    "        for outcome, count in enumerate(class_counts):\n",
    "            self.class_priors[outcome] = count / total_count\n",
    "\n",
    "    def _calc_likelihoods_multinomial(self, y_encoded):\n",
    "        for feature in self.features:\n",
    "            for outcome in np.unique(y_encoded):\n",
    "                outcome_count = np.sum(y_encoded == outcome)\n",
    "                feat_likelihood = self.X_train[feature][y_encoded == outcome].value_counts().to_dict()\n",
    "\n",
    "                for feat_val, count in feat_likelihood.items():\n",
    "                    self.likelihoods[feature][feat_val + '_' + str(outcome)] = count / outcome_count\n",
    "\n",
    "    def _calc_predictor_prior_multinomial(self):\n",
    "        for feature in self.features:\n",
    "            feat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\n",
    "            for feat_val, count in feat_vals.items():\n",
    "                self.pred_priors[feature][feat_val] = count / self.train_size\n",
    "\n",
    "    def _fit_bernoulli(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(self.y_train)\n",
    "\n",
    "        for feature in self.features:\n",
    "            self.likelihoods[feature] = {}\n",
    "            self.pred_priors[feature] = {}\n",
    "\n",
    "            for feat_val in np.unique(self.X_train[feature]):\n",
    "                self.pred_priors[feature][feat_val] = 0\n",
    "\n",
    "                for outcome in np.unique(y_encoded):\n",
    "                    self.likelihoods[feature][feat_val + '_' + str(outcome)] = 0\n",
    "                    self.class_priors[outcome] = 0\n",
    "\n",
    "        self._calc_class_prior_bernoulli(y_encoded)\n",
    "        self._calc_likelihoods_bernoulli(y_encoded)\n",
    "        self._calc_predictor_prior_bernoulli()\n",
    "\n",
    "    def _calc_class_prior_bernoulli(self, y_encoded):\n",
    "        class_counts = np.bincount(y_encoded)\n",
    "        total_count = np.sum(class_counts)\n",
    "\n",
    "        for outcome, count in enumerate(class_counts):\n",
    "            self.class_priors[outcome] = count / total_count\n",
    "\n",
    "    def _calc_likelihoods_bernoulli(self, y_encoded):\n",
    "        for feature in self.features:\n",
    "            for outcome in np.unique(y_encoded):\n",
    "                outcome_count = np.sum(y_encoded == outcome)\n",
    "                feat_likelihood = self.X_train[feature][y_encoded == outcome].value_counts().to_dict()\n",
    "\n",
    "                for feat_val, count in feat_likelihood.items():\n",
    "                    self.likelihoods[feature][feat_val + '_' + str(outcome)] = count / outcome_count\n",
    "\n",
    "    def _calc_predictor_prior_bernoulli(self):\n",
    "        for feature in self.features:\n",
    "            feat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\n",
    "            for feat_val, count in feat_vals.items():\n",
    "                self.pred_priors[feature][feat_val] = count / self.train_size\n",
    "\n",
    "    def _fit_gaussian(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(self.y_train)\n",
    "\n",
    "        for feature in self.features:\n",
    "            self.likelihoods[feature] = {}\n",
    "            self.pred_priors[feature] = {}\n",
    "\n",
    "            for outcome in np.unique(y_encoded):\n",
    "                self.class_priors[outcome] = 0\n",
    "\n",
    "        self._calc_class_prior_gaussian(y_encoded)\n",
    "        self._calc_likelihoods_gaussian(y_encoded)\n",
    "\n",
    "    def _calc_class_prior_gaussian(self, y_encoded):\n",
    "        class_counts = np.bincount(y_encoded)\n",
    "        total_count = np.sum(class_counts)\n",
    "\n",
    "        for outcome, count in enumerate(class_counts):\n",
    "            self.class_priors[outcome] = count / total_count\n",
    "\n",
    "    def _calc_likelihoods_gaussian(self, y_encoded):\n",
    "        for feature in self.features:\n",
    "            for outcome in np.unique(y_encoded):\n",
    "                X_class = self.X_train[feature][y_encoded == outcome]\n",
    "                class_mean = np.mean(X_class)\n",
    "                class_std = np.std(X_class)\n",
    "                self.likelihoods[feature][outcome] = (class_mean, class_std)\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        X = np.array(X)\n",
    "\n",
    "        for query in X:\n",
    "            probs_outcome = {}\n",
    "\n",
    "            for outcome in np.unique(self.y_train):\n",
    "                prior = self.class_priors[outcome]\n",
    "                likelihood = 1\n",
    "                evidence = 1\n",
    "\n",
    "                for feat, feat_val in zip(self.features, query):\n",
    "                    if feat_val in self.likelihoods[feat]:\n",
    "                        class_mean, class_std = self.likelihoods[feat][feat_val]\n",
    "                        likelihood *= self._calc_gaussian_likelihood(feat_val, class_mean, class_std)\n",
    "                    else:\n",
    "                        likelihood *= 0\n",
    "\n",
    "                    evidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "                posterior = (likelihood * prior) / evidence\n",
    "                probs_outcome[outcome] = posterior\n",
    "\n",
    "            result = max(probs_outcome, key=lambda x: probs_outcome[x])\n",
    "            results.append(result)\n",
    "\n",
    "        return np.array(results)\n",
    "\n",
    "    def _calc_gaussian_likelihood(self, x, mean, std):\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "import numpy as np \n",
    "import pandas as pd \t\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "\n",
    "\t\"\"\"\tscore = (y_true - y_pred) / len(y_true) \"\"\"\n",
    "\n",
    "\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n",
    "\n",
    "def pre_processing(df):\n",
    "\n",
    "\t\"\"\" partioning data into features and target \"\"\"\n",
    "\n",
    "\tX = df.drop([df.columns[-1]], axis = 1)\n",
    "\ty = df[df.columns[-1]]\n",
    "\n",
    "\treturn X, y\n",
    "\n",
    "\n",
    "\n",
    "class  NaiveBayes:\n",
    "\n",
    "\t\"\"\"\n",
    "\t\tBayes Theorem:\n",
    "\t\t\t\t\t\t\t\t\t\tLikelihood * Class prior probability\n",
    "\t\t\t\tPosterior Probability = -------------------------------------\n",
    "\t\t\t\t\t\t\t\t\t\t\tPredictor prior probability\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\t\t  \t\t\t P(x|c) * p(c)\n",
    "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
    "\t\t\t\t\t\t\t\t\t\t\t  P(x)\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t\tAttributes:\n",
    "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
    "\t\t\t\tclass_priors: Prior probabilities of classes \n",
    "\t\t\t\tpred_priors: Prior probabilities of features \n",
    "\t\t\t\tfeatures: All features of dataset\n",
    "\t\t\"\"\"\n",
    "\t\tself.features = list\n",
    "\t\tself.likelihoods = {}\n",
    "\t\tself.class_priors = {}\n",
    "\t\tself.pred_priors = {}\n",
    "\n",
    "\t\tself.X_train = np.array\n",
    "\t\tself.y_train = np.array\n",
    "\t\tself.train_size = int\n",
    "\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\n",
    "\t\tself._calc_class_prior()\n",
    "\t\tself._calc_likelihoods()\n",
    "\t\tself._calc_predictor_prior()\n",
    "\n",
    "\tdef _calc_class_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
    "\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
    "\n",
    "\tdef _calc_likelihoods(self):\n",
    "\n",
    "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
    "\n",
    "\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
    "\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\n",
    "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "\n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
    "\n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\n",
    "\t\treturn np.array(results)\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tX, y = pre_processing(df)\n",
    "\tnb_clf = NaiveBayes()\n",
    "\tnb_clf.fit(X, y)\n",
    "\n",
    "\tprint(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
    "\t\n",
    "\t# #Query 1:\n",
    "\t# query = np.array([['Rainy','Mild', 'Normal', 't']])\n",
    "\t# print(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "\t# #Query 2:\n",
    "\t# query = np.array([['Overcast','Cool', 'Normal', 't']])\n",
    "\t# print(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "\t# #Query 3:\n",
    "\t# query = np.array([['Sunny','Hot', 'High', 't']])\n",
    "\t# print(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "model = NaiveBayesClassifier()\n",
    "model.fit(X, y, classifier_type='multinomial')\n",
    "y_pred = model.predict(X)\n",
    "### **4. Split Data**\n",
    "# 80/20 train/test split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "### **5. Define Metric**\n",
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the predicted classes.\n",
    "\n",
    "    Args:\n",
    "        y_true: A numpy array of the true class labels.\n",
    "        y_pred: A numpy array of the predicted class labels.\n",
    "\n",
    "    Returns:\n",
    "        The accuracy of the predicted classes.\n",
    "    \"\"\"\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "### **5. Predict using Multinomial NB**\n",
    "# Create an instance of the NaiveBayesClassifier class\n",
    "classifier = NaiveBayesClassifier()\n",
    "\n",
    "# Fit the classifier on your training data\n",
    "classifier.fit(X_train, y_train, classifier_type='multinomial')\n",
    "\n",
    "# Make predictions on your test data\n",
    "predictions = classifier.predict(X_test)\n",
    "print(f\"Test accuracy: {accuracy(y_test, predictions):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
